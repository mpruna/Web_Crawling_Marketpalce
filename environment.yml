name: web_scrapers
channels:
  - conda-forge
  - defaults
dependencies:
  - _libgcc_mutex=0.1=conda_forge
  - _openmp_mutex=4.5=1_gnu
  - ca-certificates=2020.6.20=hecda079_0
  - certifi=2020.6.20=py38h924ce5b_2
  - ld_impl_linux-64=2.35=h769bd43_9
  - libffi=3.2.1=he1b5a44_1007
  - libgcc-ng=9.3.0=h5dbcf3e_17
  - libgomp=9.3.0=h5dbcf3e_17
  - libstdcxx-ng=9.3.0=h2ae2ef3_17
  - ncurses=6.2=he1b5a44_2
  - openssl=1.1.1h=h516909a_0
  - pip=20.2.3=py_0
  - python=3.8.6=h852b56e_0_cpython
  - python_abi=3.8=1_cp38
  - readline=8.0=he28a2e2_2
  - setuptools=49.6.0=py38h924ce5b_2
  - sqlite=3.33.0=h4cf870e_1
  - tk=8.6.10=hed695b0_1
  - wheel=0.35.1=pyh9f0ad1d_0
  - xz=5.2.5=h516909a_1
  - zlib=1.2.11=h516909a_1010
  - pip:
    - attrs==20.2.0
    - automat==20.2.0
    - beautifulsoup4==4.9.3
    - cffi==1.14.3
    - chardet==3.0.4
    - constantly==15.1.0
    - cryptography==3.1.1
    - cssselect==1.1.0
    - daemonize==2.5.0
    - fake-useragent==0.1.11
    - faker==4.14.0
    - hyperlink==20.0.1
    - idna==2.10
    - incremental==17.5.0
    - install==1.3.4
    - itemadapter==0.1.1
    - itemloaders==1.0.3
    - jmespath==0.10.0
    - lxml==4.5.2
    - mechanicalsoup==0.12.0
    - numpy==1.19.4
    - pandas==1.1.4
    - parsel==1.6.0
    - protego==0.1.16
    - pyasn1==0.4.8
    - pyasn1-modules==0.2.8
    - pycparser==2.20
    - pydispatcher==2.0.5
    - pyhamcrest==2.0.2
    - pyopenssl==19.1.0
    - python-dateutil==2.8.1
    - pytz==2020.4
    - queuelib==1.5.0
    - requests==2.24.0
    - scrapy==2.4.0
    - scrapy-fake-useragent==1.4.4
    - secure-smtplib==0.1.1
    - service-identity==18.1.0
    - six==1.15.0
    - slack-sdk==3.0.0b0
    - snakeviz==2.1.0
    - soupsieve==2.0.1
    - text-unidecode==1.3
    - tornado==6.1
    - twisted==20.3.0
    - urllib3==1.25.10
    - w3lib==1.22.0
    - zope-interface==5.1.2
prefix: /home/Tools/anaconda3/envs/web_scrapers
